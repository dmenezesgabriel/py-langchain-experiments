{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from langchain import hub\n",
    "from pprint import pprint\n",
    "from langchain.schema import Document\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models.openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "all_split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_split_docs,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embedding,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=dedent(\n",
    "        \"\"\"\n",
    "    You are a grader assesing relevance of a retrieved document to a user\n",
    "    question.\\n\n",
    "    Here is the retrieved document:\\n\\n {context} \\n\\n\n",
    "    Here is the user question: {question} \\n\n",
    "    If the document contains keywords related to the user question, grade it as\n",
    "    relevant. \\n\n",
    "    It does not need to be a stringent test, The goal is to filter out\n",
    "    errouneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate wheter the document is\n",
    "    relevant to the question. \\n\n",
    "    Provide the binary score as JSOn with a single key 'score' and no premable\n",
    "    or explanation.\n",
    "    \"\"\"\n",
    "    ),\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"Explain how the different types of agent memory work?\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "score = retrieval_grader.invoke(\n",
    "    {\"question\": question, \"context\": docs[0].page_content}\n",
    ")\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "for message in prompt.messages:\n",
    "    print(message.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_write_prompt = PromptTemplate(\n",
    "    template=dedent(\n",
    "        \"\"\"\n",
    "        You are a question re-writer that converts an input question to a\n",
    "        better version that is optmized for vectorstore retrieval. Look at the\n",
    "        initial question and formulate an improved question.\\n\n",
    "        Here is the initial question: {question} \\n. Improved question with no\n",
    "        premable:\\n\n",
    "        \"\"\"\n",
    "    ),\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "question_rewritter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewritter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search = str\n",
    "    documents: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    print(\"--- RETRIEVE ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    print(\"--- GENERATE ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\n",
    "        \"generation\": generation,\n",
    "        \"question\": question,\n",
    "        \"documents\": documents,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "    print(\"--- GRADE: CHECK DOCUMENT RELEVANCE ---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"context\": d.page_content}\n",
    "        )\n",
    "        grade = score[\"score\"]\n",
    "        if grade == \"yes\":\n",
    "            print(\"--- GRADE: DOCUMENT RELEVANT ---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"--- GRADE: DOCUMENT IRRELEVANT ---\")\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\n",
    "        \"documents\": filtered_docs,\n",
    "        \"question\": question,\n",
    "        \"web_search\": web_search,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(state):\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    better_question = question_rewritter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(state):\n",
    "    raise NotImplementedError()\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[content] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    documents.append(web_results)\n",
    "    return {\"documents\": documents, \"quesiton\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    print(\"--- ASSESS GRADED DOCUMENTS ---\")\n",
    "    web_search = \"No\"\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        print(\n",
    "            dedent(\n",
    "                \"\"\"\n",
    "                ---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION\n",
    "                TRANSFORM QUERY---\n",
    "                \"\"\"\n",
    "            )\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        print(\n",
    "            dedent(\n",
    "                \"\"\"\n",
    "                ---DECISION: ALL DOCUMENTS ARE RELEVANT TO QUESTION---\n",
    "                \"\"\"\n",
    "            )\n",
    "        )\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\"transform_query\": \"transform_query\", \"generate\": \"generate\"},\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"web_search\")\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"what are the types of agent memory?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Node '{key}':\")\n",
    "pprint(value[\"generation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
