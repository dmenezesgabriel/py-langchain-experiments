{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Dict, TypedDict\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_community.document_loaders.recursive_url_loader import (\n",
    "    RecursiveUrlLoader,\n",
    ")\n",
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://python.langchain.com/docs/expression_language/\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=20, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
    "d_reversed = list(reversed(d_sorted))\n",
    "\n",
    "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
    "    [d.page_content for d in d_reversed]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Code(BaseModel):\n",
    "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
    "    imports: str = Field(description=\"Code block import statements\")\n",
    "    code: str = Field(description=\"Code block not including import statements\")\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    keys: Dict[str, any]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0, model=\"gpt-4-0125-preview\", streaming=True)\n",
    "code_tool_ai = convert_to_openai_tool(Code)\n",
    "\n",
    "llm_with_tool = model.bind(\n",
    "    tools=[code_tool_ai],\n",
    "    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"Code\"}},\n",
    ")\n",
    "\n",
    "parser_tool = PydanticToolsParser(tools=[Code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a coding assistant with expertise in LCEL, LangChain \\\n",
    "expression language. \\n\n",
    "Here is a full set of LCEL documentation:\n",
    "\n",
    "<lcel_docs>\\n\n",
    "{context}\n",
    "</lcel_docs>\\n\n",
    "\n",
    "Answer the user question based on the above provided documentation. \\n\n",
    "Ensure any code you provided can be executed with description of the code \\\n",
    "solution. \\n\n",
    "Then list the imports. And finally list the functioning code block. \\n\n",
    "Here is the user question: \\n\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")\n",
    "\n",
    "template_addendum = \"\"\"\\n --- --- ---\\n You previously tried to solve this \\\n",
    "problem. \\n Here is your solution: \\n\\n\n",
    "\n",
    "<code>\n",
    "{generation}\n",
    "</code>\\n\n",
    "\\n--- --- ---\\n\n",
    "Here is the resulting error from code execution: \\n\\n\n",
    "\n",
    "<error>\n",
    "{error}\n",
    "</error>\\n\n",
    "\\n--- --- ---\\n\n",
    "\n",
    "Please re-try to answer this. \\n\n",
    "And finnaly list the functioning code block. Structure your answer with a \\\n",
    "description of the code solution. \\n\n",
    "Then list the imports. And finally list the functioning code block.\\n\n",
    "Here is the user question: \\n\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question> \\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        \"context\": lambda x: concatenated_content,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tool\n",
    "    | parser_tool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain.invoke({\"question\": \"How to create a RAG chain in LCEL?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    iter = state_dict[\"iterations\"]\n",
    "\n",
    "    if \"error\" in state_dict:\n",
    "        print(\"ERROR: DO IT AGAIN\")\n",
    "        error = state_dict[\"error\"]\n",
    "\n",
    "        _template = template + template_addendum\n",
    "        prompt = PromptTemplate(\n",
    "            template=_template,\n",
    "            input_variables=[\"context\", \"question\", \"error\", \"generation\"],\n",
    "        )\n",
    "\n",
    "        chain = (\n",
    "            {\n",
    "                \"context\": lambda x: concatenated_content,\n",
    "                \"question\": itemgetter(\"question\"),\n",
    "                \"generation\": itemgetter(\"generation\"),\n",
    "                \"error\": itemgetter(\"error\"),\n",
    "            }\n",
    "            | prompt\n",
    "            | llm_with_tool\n",
    "            | parser_tool\n",
    "        )\n",
    "        code_solution = chain.invoke(\n",
    "            {\n",
    "                \"question\": question,\n",
    "                \"generation\": str(code_solution[0]),\n",
    "                \"error\": error,\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        print(\"GENERATE SOLUTION\")\n",
    "        prompt = PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "        )\n",
    "\n",
    "        chain = (\n",
    "            {\n",
    "                \"context\": lambda x: concatenated_content,\n",
    "                \"question\": itemgetter(\"question\"),\n",
    "            }\n",
    "            | prompt\n",
    "            | llm_with_tool\n",
    "            | parser_tool\n",
    "        )\n",
    "\n",
    "        code_solution = chain.invoke({\"question\": question})\n",
    "    iter = iter + 1\n",
    "    return {\n",
    "        \"keys\": {\n",
    "            \"generation\": code_solution,\n",
    "            \"question\": question,\n",
    "            \"iterations\": iter,\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_code_imports(state):\n",
    "    print(\"CHECK CODE IMPORTS\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    code_solution = state_dict[\"generation\"]\n",
    "    imports = code_solution[0][\"imports\"]\n",
    "    iter = state_dict[\"iterations\"]\n",
    "\n",
    "    try:\n",
    "        exec(imports)\n",
    "    except Exception as e:\n",
    "        print(\"CODE IMPORT CHECK FAILED\")\n",
    "        error = f\"Execution error: {e}\"\n",
    "        if \"error\" in state_dict:\n",
    "            error_prev_runs = state_dict[\"error\"]\n",
    "            error = error_prev_runs + \"\\n --- Most Recent Error ---\\n\" + error\n",
    "    else:\n",
    "        print(\"CODE IMPORT SUCCESS\")\n",
    "        error = \"None\"\n",
    "    return {\n",
    "        \"keys\": {\n",
    "            \"generation\": code_solution,\n",
    "            \"question\": question,\n",
    "            \"error\": error,\n",
    "            \"iterations\": iter,\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_code_execution(state):\n",
    "    print(\"--- CHECK CODE EXECUTION ---\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    code_solution = state_dict[\"generation\"]\n",
    "    prefix = code_solution[0][\"prefix\"]\n",
    "    imports = code_solution[0][\"imports\"]\n",
    "    code = code_solution[0][\"code\"]\n",
    "    code_block = imports + \"\\n\\n\" + code\n",
    "    iter = state_dict[\"iterations\"]\n",
    "\n",
    "    try:\n",
    "        exec(code_block)\n",
    "    except Exception as e:\n",
    "        print(\"CODE EXECUTION FAILED\")\n",
    "        if \"error\" in state_dict:\n",
    "            error_prev_runs = state_dict[\"error\"]\n",
    "            error = error_prev_runs + \"\\n --- Most Recent Error ---\\n\" + str(e)\n",
    "    else:\n",
    "        print(\"CODE BLOCK CHECK: SUCCESS\")\n",
    "        error = \"None\"\n",
    "    return {\n",
    "        \"keys\": {\n",
    "            \"generation\": code_solution,\n",
    "            \"question\": question,\n",
    "            \"error\": error,\n",
    "            \"iterations\": iter,\n",
    "            \"prefix\": prefix,\n",
    "            \"imports\": imports,\n",
    "            \"code\": code,\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_check_code_exec(state):\n",
    "    print(\"DECIDE TO TEST CODE EXECUTION\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    code_solution = state_dict[\"generation\"]\n",
    "    error = state_dict[\"error\"]\n",
    "\n",
    "    if error == \"None\":\n",
    "        print(\"DECISION: TEST CODE EXECUTION\")\n",
    "        return \"check_code_execution\"\n",
    "    else:\n",
    "        print(\"DECISION: RE-TRY SOLUTION\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_finish(state):\n",
    "    print(\"DECIDE TO FINISH\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    error = state_dict[\"error\"]\n",
    "\n",
    "    if error == \"None\" or iter == 3:\n",
    "        print(\"DECISION: TEST CODE EXECUTION\")\n",
    "        return \"end\"\n",
    "    else:\n",
    "        print(\"DECISION: RE-TRY SOLUTION\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"check_code_imports\", check_code_imports)\n",
    "workflow.add_node(\"check_code_execution\", check_code_execution)\n",
    "\n",
    "workflow.set_entry_point(\"generate\")\n",
    "workflow.add_edge(\"generate\", \"check_code_imports\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_code_imports\",\n",
    "    decide_to_check_code_exec,\n",
    "    {\"check_code_execution\": \"check_code_execution\", \"generate\": \"generate\"},\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_code_execution\",\n",
    "    decide_to_finish,\n",
    "    {\"end\": END, \"generate\": \"generate\"},\n",
    ")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"I'm passing text key 'foo' to my prompt and want to process it with a function, process_text(...), prior to the prompt.\"\n",
    "config = {\"recursion_limit\": 50}\n",
    "answer = app.invoke(\n",
    "    {\"keys\": {\"question\": question, \"iterations\": 0}}, config=config\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
